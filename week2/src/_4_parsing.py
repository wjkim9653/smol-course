import json
from pathlib import Path
import re
from datasets import Dataset, DatasetDict
from huggingface_hub import login, create_repo, HfApi
from tqdm import tqdm
from pprint import pprint

# âœ… ì„¤ì •
INPUT_JSONL = "../data/mmlu_generated_qa.jsonl"  # ì‚¬ìš©ì jsonl íŒŒì¼ ê²½ë¡œ
# HF_REPO_NAME = "your-username/high-school-chemistry"  # ì—…ë¡œë“œí•  HF repo ì´ë¦„
# HF_TOKEN = "your_hf_token"  # Hugging Face access token
SUBJECT = "high_school_chemistry"

def parse_qa_item(raw_text: str) -> dict:
    """
    ë‹¤ì–‘í•œ í¬ë§·ì„ ëŒ€ì‘í•˜ëŠ” robust QA íŒŒì„œ
    """
    # ì¤‘ê´„í˜¸ ë¸”ëŸ­ ì¶”ì¶œ
    match = re.search(r"\{(.*)\}", raw_text, re.DOTALL)
    if not match:
        raise ValueError(f"Cannot extract main block from:\n{raw_text[:200]}")

    content = match.group(1).strip()

    # ì‹œë„ 1ï¸âƒ£: JSON í˜•íƒœ ì‹œë„
    try:
        normalized = re.sub(r'(\b\w+\b):', r'"\1":', content)  # "question": ...
        obj = json.loads(normalized)
        question = obj.get("question", "").strip()
        choices = obj.get("choices", [])
        answer = obj.get("answer", "").strip()

        if isinstance(choices, list) and all(isinstance(c, str) for c in choices):
            if answer in ["A", "B", "C", "D"]:
                answer_letter = answer
            elif answer in choices:
                answer_letter = chr(ord("A") + choices.index(answer))
            else:
                raise ValueError(f"Answer '{answer}' not found in choices: {choices}")
            
            return {
                "question": question,
                "choices": choices,
                "answer": answer_letter,
                "subject": "high_school_chemistry"
            }
    except Exception:
        pass  # fallthrough

    # ì‹œë„ 2ï¸âƒ£: YAML-like with - A) choices
    question = None
    choices = []
    answer = None

    lines = [line.strip() for line in content.splitlines() if line.strip()]
    i = 0
    while i < len(lines):
        line = lines[i]

        # question
        if "question" in line:
            q_match = re.match(r'"?question"?\s*:\s*(.*)', line)
            if q_match:
                question = q_match.group(1).strip()

        # choices
        elif "choices" in line:
            i += 1
            while i < len(lines) and lines[i].startswith("-"):
                choice_match = re.match(r"-\s*[A-D]\)\s*(.*)", lines[i])
                if choice_match:
                    choices.append(choice_match.group(1).strip())
                i += 1
            continue  # already incremented

        # answer
        elif "answer" in line:
            a_match = re.match(r'"?answer"?\s*:\s*("?)([A-D]|.+?)\1$', line)
            if a_match:
                answer_raw = a_match.group(2).strip()
                if answer_raw in ["A", "B", "C", "D"]:
                    answer = answer_raw
                elif answer_raw in choices:
                    answer = chr(ord("A") + choices.index(answer_raw))
        i += 1

    # ê²°ê³¼ í™•ì¸
    if not (question and choices and answer):
        raise ValueError(f"Unparsed QA item:\n{raw_text[:300]}")
    
    return {
        "question": question,
        "choices": choices,
        "answer": answer,
        "subject": "high_school_chemistry"
    }

def load_and_parse_jsonl(path: str):
    data = []
    with open(path, "r", encoding="utf-8") as f:
        for line in tqdm(f, desc="Parsing"):
            entry = json.loads(line)
            try:
                parsed = parse_qa_item(entry["qa_item"])
                data.append(parsed)
            except Exception as e:
                print(f"âš ï¸ Parse error: {e}")
                continue
    return data

def save_to_jsonl(data: list, output_path: str):
    with open(output_path, "w", encoding="utf-8") as f:
        for entry in data:
            json.dump(entry, f, ensure_ascii=False)
            f.write("\n")

def push_to_hub(dataset: Dataset, repo_name: str, hf_token: str):
    login(token=hf_token)
    
    # Repoê°€ ì—†ë‹¤ë©´ ìƒì„±
    api = HfApi()
    if repo_name not in [d.repo_id for d in api.list_datasets()]:
        create_repo(repo_id=repo_name, repo_type="dataset", token=hf_token)

    # push to Hub
    dataset.push_to_hub(repo_name)

def main():
    print("ğŸ” JSONL íŒŒì‹± ì¤‘...")
    parsed_data = load_and_parse_jsonl(INPUT_JSONL)
    pprint(parsed_data)
    print(f"ë³€í™˜ëœ MMLU Format Dataset ê°œìˆ˜: {len(parsed_data)}")
    save_to_jsonl(parsed_data, "../data/mmlu_official_format.jsonl")
    
    print("ğŸ“¦ Datasets í¬ë§·ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
    dataset = Dataset.from_list(parsed_data)

    # print("ğŸš€ Hugging Face Hubë¡œ ì—…ë¡œë“œ ì¤‘...")
    # push_to_hub(dataset, HF_REPO_NAME, HF_TOKEN)
    # print("âœ… ì—…ë¡œë“œ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
